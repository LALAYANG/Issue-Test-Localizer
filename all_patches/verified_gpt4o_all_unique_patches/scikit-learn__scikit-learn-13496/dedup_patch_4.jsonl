{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 17608bc..1a23592 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -147,6 +147,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n         ``offset_ = -0.5``, making the decision function independent from the\n         contamination parameter.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n     Notes\n     -----\n     The implementation is based on an ensemble of ExtraTreeRegressor. The\n@@ -173,7 +178,8 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -189,6 +195,7 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             random_state=random_state,\n             verbose=verbose)\n \n+        self.warm_start = warm_start\n         self.behaviour = behaviour\n         self.contamination = contamination\n \n@@ -274,6 +281,10 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_samples = int(self.max_samples * X.shape[0])\n \n         self.max_samples_ = max_samples\n+\n+        # Update n_estimators if warm_start is True\n+        if self.warm_start and hasattr(self, \"estimators_\"):\n+            self.n_estimators += len(self.estimators_)\n         max_depth = int(np.ceil(np.log2(max(max_samples, 2))))\n         super()._fit(X, y, max_samples,\n                      max_depth=max_depth,\n"}
