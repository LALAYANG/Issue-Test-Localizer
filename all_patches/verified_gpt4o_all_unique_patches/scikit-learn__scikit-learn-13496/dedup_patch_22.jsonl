{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-13496", "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 17608bc..f5b1a32 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -173,6 +173,7 @@ class IsolationForest(BaseBagging, OutlierMixin):\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n+                 warm_start=False,\n                  verbose=0):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n@@ -187,9 +188,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             max_features=max_features,\n             n_jobs=n_jobs,\n             random_state=random_state,\n+            warm_start=warm_start,\n             verbose=verbose)\n+        self.warm_start = warm_start\n \n         self.behaviour = behaviour\n+        self.warm_start = warm_start\n         self.contamination = contamination\n \n     def _set_oob_score(self, X, y):\n@@ -212,6 +216,11 @@ class IsolationForest(BaseBagging, OutlierMixin):\n             efficiency. Sparse matrices are also supported, use sparse\n             ``csc_matrix`` for maximum efficiency.\n \n+        warm_start : bool, optional (default=False)\n+            When set to ``True``, reuse the solution of the previous call to fit\n+            and add more estimators to the ensemble, otherwise, just fit a whole\n+            new forest. See :term:`the Glossary <warm_start>`.\n+\n         sample_weight : array-like, shape = [n_samples] or None\n             Sample weights. If None, then samples are equally weighted.\n \n"}
