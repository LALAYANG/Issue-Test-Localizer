{"model_name_or_path": "agentless", "instance_id": "pydata__xarray-3151", "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex b8f5640..163b68c 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -27,21 +27,22 @@ def _infer_concat_order_from_coords(datasets):\n             indexes = [ds.indexes.get(dim) for ds in datasets]\n             if any((index is None for index in indexes)):\n                 raise ValueError('Every dimension needs a coordinate for inferring concatenation order')\n-            if not all((index.equals(indexes[0]) for index in indexes[1:])):\n-                concat_dims.append(dim)\n-                if all((index.is_monotonic_increasing for index in indexes)):\n-                    ascending = True\n-                elif all((index.is_monotonic_decreasing for index in indexes)):\n-                    ascending = False\n-                else:\n-                    raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n-                if any((index.size == 0 for index in indexes)):\n-                    raise ValueError('Cannot handle size zero dimensions')\n-                first_items = pd.Index([index.take([0]) for index in indexes])\n-                series = first_items.to_series()\n-                rank = series.rank(method='dense', ascending=ascending)\n-                order = rank.astype(int).values - 1\n-                tile_ids = [tile_id + (position,) for tile_id, position in zip(tile_ids, order)]\n+            if any((index.size == 0 for index in indexes)):\n+                raise ValueError('Cannot handle size zero dimensions')\n+            if all((index.equals(indexes[0]) for index in indexes[1:])):\n+                continue\n+            concat_dims.append(dim)\n+            if all((index.is_monotonic_increasing for index in indexes)):\n+                ascending = True\n+            elif all((index.is_monotonic_decreasing for index in indexes)):\n+                ascending = False\n+            else:\n+                raise ValueError('Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets'.format(dim))\n+            first_items = pd.Index([index.take([0]) for index in indexes])\n+            series = first_items.to_series()\n+            rank = series.rank(method='dense', ascending=ascending)\n+            order = rank.astype(int).values - 1\n+            tile_ids = [tile_id + (position,) for tile_id, position in zip(tile_ids, order)]\n     if len(datasets) > 1 and (not concat_dims):\n         raise ValueError('Could not find any dimension coordinates to use to order the datasets for concatenation')\n     combined_ids = OrderedDict(zip(tile_ids, datasets))\n@@ -115,11 +116,6 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all', coords='\n         combined_ids, concat_dims = _infer_concat_order_from_coords(list(datasets_with_same_vars))\n         _check_shape_tile_ids(combined_ids)\n         concatenated = _combine_nd(combined_ids, concat_dims=concat_dims, data_vars=data_vars, coords=coords, fill_value=fill_value)\n-        for dim in concatenated.dims:\n-            if dim in concatenated:\n-                indexes = concatenated.indexes.get(dim)\n-                if not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):\n-                    raise ValueError('Resulting object does not have monotonic global indexes along dimension {}'.format(dim))\n         concatenated_grouped_by_data_vars.append(concatenated)\n     return merge(concatenated_grouped_by_data_vars, compat=compat, fill_value=fill_value)\n _CONCAT_DIM_DEFAULT = '__infer_concat_dim__'"}
