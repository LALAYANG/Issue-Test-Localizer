{"model_name_or_path": "agentless", "instance_id": "scikit-learn__scikit-learn-10908", "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 7e240fc..cde94ea 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -736,6 +736,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n                     % max_features)\n         self.ngram_range = ngram_range\n         self.vocabulary = vocabulary\n+        if vocabulary is not None:\n+            self.vocabulary_ = vocabulary\n         self.binary = binary\n         self.dtype = dtype\n \n@@ -953,7 +955,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         if not hasattr(self, 'vocabulary_'):\n             self._validate_vocabulary()\n \n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n \n         # use the same matrix-building strategy as fit_transform\n         _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n@@ -973,7 +976,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         X_inv : list of arrays, len = n_samples\n             List of arrays of terms.\n         \"\"\"\n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n \n         if sp.issparse(X):\n             # We need CSR format for fast row manipulations.\n@@ -993,7 +997,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n-        self._check_vocabulary()\n+        if not hasattr(self, 'vocabulary_'):\n+            self._validate_vocabulary()\n \n         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n                                      key=itemgetter(1))]\n"}
